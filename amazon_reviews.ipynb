{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "- Understand the Dataset & perform the necessary cleanup.\n",
    "- Build a strong Topic Modelling Algorithm to classify the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('product_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From this we can see that this Dataset contains a lot of columns. For the purpose of our analyses, we only need a few"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For reference, here is a description of each column \n",
    "\n",
    "- **id:** Unique identifier for each product.\n",
    "- **asins:** ASIN (Amazon Standard Identification Number) associated with the product.\n",
    "- **brand:** Brand of the product.\n",
    "- **categories:** Categories to which the product belongs.\n",
    "- **colors:** Colors available for the product.\n",
    "- **dateAdded:** Date when the product was added.\n",
    "- **dateUpdated:** Date when the product information was last updated.\n",
    "- **dimension:** Dimensions of the product.\n",
    "- **ean:** EAN (European Article Number) associated with the product.\n",
    "- **keys:** Unique keys associated with the product.\n",
    "- **manufacturer:** Manufacturer of the product.\n",
    "- **manufacturerNumber:** Manufacturer number for the product.\n",
    "- **name:** Name of the product.\n",
    "- **prices:** Prices associated with the product, including currency and date information.\n",
    "- **reviews.date:** Date when the review was posted.\n",
    "- **reviews.doRecommend:** Indicates whether the reviewer recommends the product.\n",
    "- **reviews.numHelpful:** Number of users who found the review helpful.\n",
    "- **reviews.rating:** Rating given by the reviewer.\n",
    "- **reviews.sourceURLs:** URLs to the source of the reviews.\n",
    "- **reviews.text:** Text content of the review.\n",
    "- **reviews.title:** Title of the review.\n",
    "- **reviews.userCity:** City of the reviewer.\n",
    "- **reviews.userProvince:** Province of the reviewer.\n",
    "- **reviews.username:** Username of the reviewer.\n",
    "- **sizes:** Sizes available for the product.\n",
    "- **upc:** UPC (Universal Product Code) associated with the product.\n",
    "- **weight:** Weight of the product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get an easier idea of all the columns we are working with, let us see how many exist\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a new df including more of what is actually relevant\n",
    "relevant_columns = ['id', 'asins', 'brand', 'categories', 'colors', 'manufacturer',\n",
    "        'name', 'prices', 'reviews.date',\n",
    "       'reviews.doRecommend', 'reviews.numHelpful', 'reviews.rating', 'reviews.text', 'reviews.title',\n",
    "         'sizes', 'weight']\n",
    "product_reviews = df[relevant_columns]\n",
    "product_reviews.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have a dataset with more of the information we need, we have spotted that a few columns needs restructuring\n",
    "### Specifically the prices column and the reviews date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews['prices'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews['reviews.date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change format to datetime\n",
    "product_reviews['reviews.date'] = pd.to_datetime(product_reviews['reviews.date'], format='ISO8601')\n",
    "\n",
    "# Gets rid of milliseconds\n",
    "product_reviews['reviews.date'] = product_reviews['reviews.date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "product_reviews['reviews.date'].dtype #still datetime but is stored as object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews['reviews.date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick test to make sure things are working as intended\n",
    "product_reviews['reviews.date'] > '2016-02-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that the date is fixed, we will move on to fixing the price column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a refresher here are what values in the price column look like\n",
    "prices_first_row = product_reviews['prices'][0]\n",
    "print(prices_first_row)\n",
    "print(type(prices_first_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews['prices'][220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is a lot to take in so we'll adjust it to be more presentable\n",
    "import json\n",
    "\n",
    "# convert the value that is currently a str to a list with dictionaries\n",
    "prices_1 = json.loads(prices_first_row)\n",
    "print(\"before proper formatting; \", type(prices_1))\n",
    "\n",
    "# makes it more presentable within json format\n",
    "prices_1_format = json.dumps(prices_1, indent = 3)\n",
    "print(prices_1_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For our purposes, we only want prices in USD. With the example shown above we see that there can be multiple prices in USD\n",
    "- The original price when not on sale and the sale price.\n",
    "\n",
    "## With this knowledge, we'll create two extra columns to the product reviews table and store those prices in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure all columns have a price in USD\n",
    "len(product_reviews['prices'].str.contains(\"USD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a loop(hopefully with enumerate) that takes in the prices in USD for each item\n",
    "full_prices = []\n",
    "sale_prices = []\n",
    "\n",
    "for i in product_reviews.index:\n",
    "    list_dict = json.loads(product_reviews['prices'][i])\n",
    "\n",
    "    # Initialize variables to store original and sale prices\n",
    "    original_price = float(list_dict[0]['amountMax'])\n",
    "\n",
    "\n",
    "\n",
    "    # Iterate through the list of dictionaries to find prices\n",
    "    for price_info in list_dict:\n",
    "        if price_info.get('currency') == 'USD' and price_info.get('isSale') == 'true':\n",
    "            sale_price = float(price_info['amountMax'])\n",
    "            break\n",
    "\n",
    "\n",
    "    # Append prices to respective lists\n",
    "    full_prices.append(original_price)\n",
    "    sale_prices.append(sale_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to ensure if the loop above needs to be adjusted to include a substitute value if there isnt a sale price\n",
    "print(len(sale_prices),len(full_prices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we add two columns to showcase the two prices\n",
    "product_reviews.insert(8,'fullPrice',full_prices)\n",
    "product_reviews.insert(9,'salePrice',sale_prices)\n",
    "product_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that this is done, we no longer need the original price column\n",
    "product_reviews = product_reviews.drop(columns='prices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data is finally clean and we will now move on to utilizing NLP for the following purposes\n",
    "- elaborating on how positive each review is\n",
    "    - creating a classification model to then support classifying the level of positivity\n",
    "- topic of each review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for an intro to the natural language processing toolkit and the different language packages it has. Close it when you've had a good view of the GUI\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon') # required to be used with sentiment analysis intensity\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer # for identifying the level of sentiment(neg to pos) of text\n",
    "\n",
    "# class and function of sentiment intensity analysis\n",
    "sia = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check to make sure all products have reviews.\n",
    "product_reviews['reviews.text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "\n",
    "\n",
    "translator = Translator()\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "scores_data = []\n",
    "\n",
    "for review in product_reviews['reviews.text']:\n",
    "    # Check if the review is in English\n",
    "    try:\n",
    "        if detect(review) != 'en':\n",
    "            # Translate non-English reviews to English\n",
    "            translation = translator.translate(review, dest='en').text\n",
    "            review = translation\n",
    "\n",
    "        # Analyze sentiment for the (translated or original) review\n",
    "        score = sia.polarity_scores(review)\n",
    "        scores_data.append(score)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review: {e}\")\n",
    "\n",
    "scores_data[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a column to store the positivity scores\n",
    "product_reviews.insert(15,'positivityScore',[scores_data[i]['compound'] for i in range(len(scores_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivity_level = []\n",
    "\n",
    "for i in product_reviews['positivityScore']:\n",
    "    if .66 <= i <= 1:\n",
    "        positivity_level.append(\"highly positive\")\n",
    "    elif .33 <= i < .66:\n",
    "        positivity_level.append(\"positive\")\n",
    "    elif .1 <= i < .33:\n",
    "        positivity_level.append(\"fairly positive\")\n",
    "    elif -.1 <= i < .1:\n",
    "        positivity_level.append(\"neutral\")\n",
    "    elif -.33 <= i < -.1:\n",
    "        positivity_level.append(\"fairly negative\")\n",
    "    elif -.66 <= i < -.33:\n",
    "        positivity_level.append(\"negative\")\n",
    "    elif -1 <= i < -.66:\n",
    "        positivity_level.append(\"highly negative\")\n",
    "\n",
    "\n",
    "\n",
    "product_reviews.insert(16,'positivityLevel',positivity_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll go over to creating the algorithm for identifying the topic within each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you know a specific package that you want to download you can do it like what we\n",
    "nltk.download('product_reviews_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many files are within this dataset\n",
    "from nltk.corpus import product_reviews_2\n",
    "len(product_reviews_2.fileids())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a quick look at them\n",
    "product_reviews_2.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go deep into seeing one of them,\n",
    "print(product_reviews_2.raw(fileids='Linksys_Router.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
